{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b2b9b92",
   "metadata": {},
   "source": [
    "# September 18 Meeting Notebook\n",
    "\n",
    "This notebook is to categorize the exploration taken for the project as of September 18, 2025.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "The objectives for this meeting are to:\n",
    "\n",
    "1. Run the LSTM code for Fresno Agg. Data\n",
    "2. Break down the feature vector into its components:\n",
    "    - For each component, compare sliding window length for its comparison for VFRates.\n",
    "3. Once (2) is completed, create a padding function and mask function that allows the new LSTM to take into account the individual sliding windows so see if analysis changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89137638",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa73e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the fresno aggregate data \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "import os \n",
    "\n",
    "sys.path.append(os.path.abspath('..')) \n",
    "\n",
    "df_fresno = pd.read_csv(\"../../data/Fresno_Aggregate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the head to make sure we have the right data loaded\n",
    "df_fresno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba803ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62cf507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for LSTM\n",
    "# Exclude 'Year-Month' and 'VFRate' (target variable)\n",
    "feature_columns = ['FIRE_Acres_Burned', 'PRECIP', 'WIND_EventCount', 'WIND_AvgMPH', \n",
    "\t\t\t\t  'WIND_RunMiles', 'AQI_PM25', 'AQI_PM10', 'EARTHQUAKE_Total', 'PESTICIDE_Total']\n",
    "\n",
    "# Create X (features) and y (target)\n",
    "X = df_fresno[feature_columns].values\n",
    "y = df_fresno['VFRate'].values\n",
    "\n",
    "# Plot correlation between features and VFRate\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, feature in enumerate(feature_columns):\n",
    "\tplt.subplot(3, 3, i+1)\n",
    "\tplt.scatter(df_fresno[feature], df_fresno['VFRate'])\n",
    "\tplt.xlabel(feature)\n",
    "\tplt.ylabel('VFRate')\n",
    "\tplt.title(f'{feature} vs VFRate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now what we want to do is loop through each feature and run the LSTM on each feature individually with a list of\n",
    "# sliding window sizes and see which feature and sliding window size gives us the best performance\n",
    "sliding_window_sizes = [1, 3, 6, 8, 12]\n",
    "results = []\n",
    "\n",
    "# probably need to make a function that preprocesses the \"feature vector\" for each run, turn into tensors\n",
    "# test/train split, scale, and then run the LSTM model\n",
    "def preprocess_data(X, y, feature_index, window_size, test_size=0.2):\n",
    "  # Select the feature column\n",
    "  if feature_index is not None:\n",
    "    X_feature = X[:, feature_index].reshape(-1, 1)\n",
    "  else:\n",
    "    X_feature = X # its the whole feautre set\n",
    "\n",
    "  # Create sequences for LSTM\n",
    "  X_sequences, y_sequences = [], []\n",
    "  for i in range(len(X_feature) - window_size):\n",
    "    X_sequences.append(X_feature[i:i+window_size])\n",
    "    y_sequences.append(y[i+window_size])\n",
    "\n",
    "  X_sequences = np.array(X_sequences)\n",
    "  y_sequences = np.array(y_sequences)\n",
    "\n",
    "  # Train-test split\n",
    "  split_index = int(len(X_sequences) * (1 - test_size))\n",
    "  X_train, X_test = X_sequences[:split_index], X_sequences[split_index:]\n",
    "  y_train, y_test = y_sequences[:split_index], y_sequences[split_index:]\n",
    "\n",
    "  return X_train, X_test, y_train, y_test \n",
    "\n",
    "# before we plug into the lstm we need minmax scaling too\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "def scale_data(X_train, X_test, y_train, y_test):\n",
    "  # Reshape for scaling\n",
    "  num_samples, window_size, num_features = X_train.shape\n",
    "  X_train_reshaped = X_train.reshape(-1, num_features)\n",
    "  X_test_reshaped = X_test.reshape(-1, num_features)\n",
    "\n",
    "  # Scale features\n",
    "  X_train_scaled = scaler_X.fit_transform(X_train_reshaped).reshape(num_samples, window_size, num_features)\n",
    "  X_test_scaled = scaler_X.transform(X_test_reshaped).reshape(X_test.shape[0], window_size, num_features)\n",
    "\n",
    "  # Scale target\n",
    "  y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "  y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "  return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled\n",
    "\n",
    "# below are model parameters \n",
    "# model parameters\n",
    "# lookback has been removed because we are varying the sliding window size\n",
    "hidden_size          = 32\n",
    "num_layers           = 2\n",
    "dropout              = 0.2\n",
    "learning_rate        = 0.001\n",
    "epochs               = 300\n",
    "weight_decay         = 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below is my training function for you to utilize \n",
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import date\n",
    "\n",
    "# Creating a Trainer Class to contain Training/Testing/Visualizing\n",
    "class TrainerNewNew:\n",
    "  \"\"\"\n",
    "  Trainer Class: A class that contains the training, testing, and visualization functions.\n",
    "  \"\"\"\n",
    "  def __init__(self, model, criterion, optimizer, scaler):\n",
    "    \"\"\"\n",
    "    Initialize the class. Takes in a model, crtierion for loss, optimizer, scaler.\n",
    "    \n",
    "    Inputs:\n",
    "      - Model: Neural Network model\n",
    "      - Criterion: Loss function (Typically MSELoss for time series, may look into more)\n",
    "      - Optimizer: Optimizer with learning rate added. Typically using Adam\n",
    "      - Scaler: MinMaxScaler scaler value, used for inverse transform to get actual data back\n",
    "    \"\"\"\n",
    "    self.model     = model \n",
    "    self.criterion = criterion \n",
    "    self.optimizer = optimizer\n",
    "    self.scaler    = scaler\n",
    "  \n",
    "  def train(self, X_train, y_train, X_test, y_test, epochs):\n",
    "    history = {'train_loss': [], 'test_loss': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        self.model.train()\n",
    "        output = self.model(X_train)\n",
    "        loss = self.criterion(output, y_train)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        history['train_loss'].append(loss.item())\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = self.criterion(self.model(X_test), y_test)\n",
    "                history['test_loss'].append(val_loss.item())\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - Training Loss {loss.item():.4f}, Testing Loss {val_loss.item():.4f}\")\n",
    "    \n",
    "    # Capture the final training predictions\n",
    "    self.model.eval()\n",
    "    with torch.no_grad():\n",
    "        final_train_preds = self.model(X_train).detach().cpu().numpy()\n",
    "        \n",
    "    # Also inverse transform the training data for later plotting\n",
    "    y_train_true = self.scaler.inverse_transform(y_train.cpu().numpy().reshape(-1, 1)).flatten()\n",
    "    final_train_preds_inv = self.scaler.inverse_transform(final_train_preds).flatten()\n",
    "    \n",
    "    return history, final_train_preds_inv, y_train_true\n",
    "    \n",
    "  def evaluate(self, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluation Loop. Evaluates the model and generates predictions.\n",
    "\n",
    "    Inputs:\n",
    "      - X_test: Test matrix X\n",
    "      - y_test: Test target vector y\n",
    "    \n",
    "    Outputs:\n",
    "      - y_pred: predicted target vector from the model using X_test\n",
    "      - y_true: True target vector (y_test)\n",
    "    \"\"\"\n",
    "    self.model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = self.model(X_test).detach().cpu().numpy()\n",
    "\n",
    "        # Inverse transform the predictions using the y_scaler\n",
    "        # The y_scaler was fit on a 1-D array, so the predictions should be reshaped\n",
    "        vf_pred = self.scaler.inverse_transform(preds)\n",
    "\n",
    "        # Inverse transform the true values using the y_scaler\n",
    "        # The y_scaler was fit on a 1-D array, so the true values should be reshaped\n",
    "        vf_true = self.scaler.inverse_transform(y_test.cpu().numpy())\n",
    "        \n",
    "    return vf_pred.flatten(), vf_true.flatten()\n",
    "  \n",
    "  def visualize_results(self, true, pred, county_name=\"\", model_type = \"LSTM\", title_text = \"\", show_plot = True, save_fig = False):\n",
    "    \"\"\"\n",
    "    Function to visualize the prediction vs true (test) vector\n",
    "\n",
    "    Inputs:\n",
    "      - True: True data (test or validation target vector)\n",
    "      - Pred: Prediction data from the model evaluation function\n",
    "    \"\"\"\n",
    "    if show_plot:\n",
    "      plt.figure(figsize=(12, 6))\n",
    "      plt.plot(true, label=\"True Values\")\n",
    "      plt.plot(pred[1:], label = \"Predicted Values\", linestyle=\"--\")\n",
    "      plt.title(f\"{county_name} {model_type} {title_text} True vs Predicted Valley Fever Case Rates\")\n",
    "      plt.xlabel(\"Months\")\n",
    "      plt.ylabel(\"Case Rates\")\n",
    "      plt.legend()\n",
    "      plt.grid(True)\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n",
    "    \n",
    "    if save_fig:\n",
    "      plt.figure(figsize=(12, 6))\n",
    "      plt.plot(true, label=\"True Values\")\n",
    "      plt.plot(pred[1:], label = \"Predicted Values\", linestyle=\"--\")\n",
    "      plt.title(f\"{county_name} {model_type} {title_text} LSTM True vs Predicted Valley Fever Case Rates\")\n",
    "      plt.xlabel(\"Months\")\n",
    "      plt.ylabel(\"Case Rates\")\n",
    "      plt.legend()\n",
    "      plt.grid(True)\n",
    "      plt.tight_layout()\n",
    "      img_str = f\"Project/plots/{model_type}/{county_name}_{title_text}_plot_{date.today()}.png\"\n",
    "      plt.savefig(img_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb4454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_functions import RMSELoss\n",
    "import torch.optim as optim \n",
    "\n",
    "criterion = RMSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now loop through each feature and sliding window size\n",
    "for feature_index, feature in enumerate(feature_columns):\n",
    "  # generate the feature vector and target vector\n",
    "  for window_size in sliding_window_sizes:\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X, y, feature_index, window_size)\n",
    "    \n",
    "    # scale the data\n",
    "    X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = scale_data(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Convert to PyTorch tensors and reshape for LSTM input\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    X_test_tensor  = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).view(-1, 1)\n",
    "    y_test_tensor  = torch.tensor(y_test_scaled, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = LSTM(input_size=1, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # Create Trainer instance\n",
    "    trainer = TrainerNewNew(model, criterion, optimizer, scaler_y)\n",
    "    \n",
    "    # Train the model\n",
    "    history, train_preds_inv, y_train_true = trainer.train(X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, epochs)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred_inv, y_true_inv = trainer.evaluate(X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    # Calculate RMSE for test set\n",
    "    rmse = np.sqrt(np.mean((y_pred_inv - y_true_inv) ** 2))\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'feature': feature,\n",
    "        'window_size': window_size,\n",
    "        'rmse': rmse\n",
    "    })\n",
    "    \n",
    "    print(f\"Feature: {feature}, Window Size: {window_size}, Test RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    # Optionally visualize results for each run\n",
    "    #trainer.visualize_results(y_true_inv, y_pred_inv, county_name=\"Fresno\", model_type=\"LSTM\", title_text=f\"{feature} Window {window_size}\", show_plot=True, save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafec4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f97f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the code above, lets run the LSTM model on the full feature vector X with the sliding window varying\n",
    "# vary the window size as well here\n",
    "window_size = [1, 2, 4, 6, 8, 12] # change the index to vary the window size\n",
    "# prep the data using the function you made \n",
    "print(X.shape)\n",
    "for window_size in sliding_window_sizes:\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X, y, feature_index=None, window_size=window_size)\n",
    "    # scale the data\n",
    "    X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = scale_data(X_train, X_test, y_train, y_test)\n",
    "    # Convert to PyTorch tensors and reshape for LSTM input\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    X_test_tensor  = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).view(-1, 1)\n",
    "    y_test_tensor  = torch.tensor(y_test_scaled, dtype=torch.float32).view(-1, 1) \n",
    "    # Initialize the model\n",
    "    model = LSTM(input_size=len(feature_columns), hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    # Create Trainer instance\n",
    "    trainer = TrainerNewNew(model, criterion, optimizer, scaler_y)\n",
    "    # Train the model\n",
    "    history, train_preds_inv, y_train_true = trainer.train(X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, epochs)\n",
    "    # Evaluate the model\n",
    "    y_pred_inv, y_true_inv = trainer.evaluate(X_test_tensor, y_test_tensor)\n",
    "    # Calculate RMSE for test set\n",
    "    rmse = np.sqrt(np.mean((y_pred_inv - y_true_inv) ** 2))\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'feature': 'All Features',\n",
    "        'window_size': window_size,\n",
    "        'rmse': rmse\n",
    "    })  \n",
    "\n",
    "    # visualize the output\n",
    "    trainer.visualize_results(y_true_inv, y_pred_inv, county_name=\"Fresno\", model_type=\"LSTM\", title_text=f\"All Features Window {window_size}\", show_plot=True, save_fig=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ffc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this data frame as a csv \n",
    "results_df.to_csv(\"../../data/fresno_lstm_feature_window_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c448963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each feature, what is the sliding window that has the lowest RMSE?\n",
    "best_results = results_df.loc[results_df.groupby('feature')['rmse'].idxmin()]\n",
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ca0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this as a csv as well\n",
    "best_results.to_csv(\"../../data/fresno_lstm_best_feature_window_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9abcc52",
   "metadata": {},
   "source": [
    "# Creating custom length feature vectors with individual sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc792048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
